from pathlib import Path
from typing import Dict, Set

import pandas as pd
from snakemake.utils import min_version

# require minimum snakemake version
min_version("6.10.0")


# =====================================
# Workflow config items
configfile: "config/config.yaml"


samplesheet = pd.read_csv(config["samplesheet"], index_col="sample")
containers: Dict[str, str] = config["containers"]
# =====================================

# =====================================
# Constants for workflow
GB = 1_024
rules_dir = Path("workflow/rules").resolve()
env_dir = Path("workflow/envs").resolve()
scripts_dir = Path("workflow/scripts").resolve()
nfs_data_dir = Path(config["nfs_data_dir"]).resolve()
fast5_dir = nfs_data_dir / "nanopore/fast5"
illumina_dir = nfs_data_dir / "illumina"
data_dir = Path("data").resolve()
GUPPY_VERSION = containers["guppy-gpu"].split(":")[-1]
rule_log_dir = Path("logs/stderr")
decontam_db = data_dir / "decontam_db"
results = Path("results").resolve()
ont_results = results / "nanopore"
illumina_results = results / "illumina"
report_dir = results / "report"
BWA_EXTNS = [".amb", ".ann", ".bwt", ".pac", ".sa"]
# =====================================


# =====================================
# Generate the set of required output files from the pipeline
output: Set[Path] = set()
filter_logfiles: Set[Path] = set()
mykrobe_results: Set[Path] = set()
rasusa_logs: Set[Path] = set()
for sample, row in samplesheet.iterrows():
    output.add(data_dir / f"fastqs/guppy_v{GUPPY_VERSION}/{sample}.fq.gz")
    filter_logfiles.add(rule_log_dir / "filter_contamination/{sample}.log")
    mykrobe_results.add(amr_dir / f"{sample}.mykrobe.json")
    rasusa_logs.add(rule_log_dir / f"subsample_reads/{sample}.log")
output.add(report_dir / "composition.html")
output.add(report_dir / "amr.html")
# =====================================


rule all:
    input:
        output,


include: rules_dir / "basecall.smk"
include: rules_dir / "qc.smk"
include: rules_dir / "amr.smk"
include: rules_dir / "report.smk"
